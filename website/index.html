<!DOCTYPE html>
<html lang="en">

<head>
    <link rel="stylesheet" href="./libs/bootstrap.min.css">
    <link rel="stylesheet" href="./style.css">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Physical Modelling Synthesis Assignment</title>
</head>

<body style="font-size: 125%; text-align: justify;" class="h-100">
    <div class="container-fluid text-light h-100 w-100 mh-100 mw-100" style="background-color: rgba(33, 37, 41, 0.975)">
        <div class="bg-dark h-100 mh-100 p-4" style="margin: 0 12% 0 12%;">
            <div>
                <div class="d-flex justify-content-between">
                    <h1>ELE00102M: Physical Modelling Synthesis</h1>
                    <p class="h4 mt-3">Y3846756</p>
                </div>
                <h2>Sound Synthesis Report</h2>
                <hr>
            </div>
            <div>
                <h3>1. Introduction</h3>
                <p>Software implementations of physical models offer exceptional quality and expressivity when imitating real acoustic instruments [1]. These implementations replicate the causal interactions of vibrating systems and can accurately reproduce the idiosyncrasies and unique characteristics of an instrument [2]. Traditional physical modelling starts with a continuous differential equation of the mechanical system and then numerically discretises this using finite difference methods, such as the Finite Difference Time Domain (FDTD) approach. Finite difference solutions work by splitting sections of the model into a 1D line, or 2D or 3D mesh of nodes, then approximating the relevant differential equation by a finite difference equivalent calculated based on values at neighbouring points, and taking into account the given boundary and initial conditions of the system [3]. This effectively “brute forces” the calculation and is therefore very computationally demanding, meaning that historically it has been an unfeasible approach, especially for real-time systems [1].</p>
                <p>A more computationally friendly alternative is the digital waveguide methods. The digital waveguide method attempts to explicitly simulate the travelling waves of a system as opposed to a real, physical variable within the system [1]. The 1D digital waveguide for an ideal, infinite, undamped string can be demonstrated by first considering the differential wave equation for this ideal string:</p>
                <p style="font-size: 125%;">
                    $$\frac{\partial y(t, x)}{\partial t^2} = c^2\frac{\partial y(t, x)}{\partial x^2}$$
                </p>
                <p>This can then be solved by the travelling wave solution:</p>
                <p style="font-size: 125%;">
                    $$y(t, x) = y^+(t - \frac{x}{c}) + y^-(t + \frac{x}{c})$$
                </p>
                <p>where \(y^-\) denotes the left travelling wave and \(y^+\)denotes the right travelling wave. This can then be easily modified to use discrete sampling points:</p>
                <figure style="font-size: 125%;">
                    $$y(nT, mX) = y^+(n - m) + y^-(n + m)$$
                </figure>
                <p>
                    where \(nT\) is the sampling interval and \(mX\) are the sampling points, where \(X=cT\) and \(c≈343 m/s\) (the speed of sound). A simple example of some MATLAB&#174; code implementing this is shown in Figure 1, alongside the wave this produces on the string in Figure 2. The red and blue waves show the left and right travelling waves, and the yellow wave shows the total displacement of the string.
                </p>
                <div class="d-flex justify-content-around">
                    <figure class="figure">
                        <pre class="figure-img" style="overflow-y: hidden;">
                            <code>

for n = 1:N
    % Shift samples along left delay line, use dummy for last value
    left = [left(2:L), 0];
    % Shift samples along right delay line and add reflection from left
    % delay line to the start
    right = [-left(1), right(1:L-1)];
    % Add reflection from end of right delay line to end of left delay line
    left(L) = -right(L);
    % Sum the outputs of the two delay lines at pickup points
    out(n) = (left(pickup) + right(pickup));
end
                            </code>
                        </pre>
                        <figcaption style="font-style: italic;" class="figure-caption text-light">Figure 1: Example block of MATLAB code showing the main loop in a 1D Digital Waveguide implementation.</figcaption>
                    </figure>
                    <figure class="figure">
                        <img class="figure-img" height="254px" width="500px" src="./string-pluck.gif" alt="">
                        <figcaption style="font-style: italic;" class="figure-caption text-light">Figure 2: Simulated travelling waves and wave displacement on an ideal string.</figcaption>
                    </figure>
                </div>
                <p>
                    This makes it simple and efficient to implement in software using delay lines and is what was used in Yamaha’s VL1 synthesizer from 1993 [4]. There are also modern commercially available physical modelling software plugins, such as Pianoteq, an award-winning virtual instrument targeted at primarily modelling pianos [5]. 
                </p>
                <p>
                    The 1D digital waveguide has also been expanded to 2D and 3D models [6]. The 2D model for an ideal membrane takes several of the bi-directional delay lines of the 1D model and connects these together at lossless, 4-port scattering junctions [6]. A block diagram showing a small section of a 2D digital waveguide mesh is shown in Figure 3.
                </p>
                <figure class="figure w-100">
                    <div class="d-flex">
                        <img class="figure-img mx-auto" src="./2d-waveguide-mesh.png" alt="">
                    </div>
                    <figcaption style="font-style: italic;" class="figure-caption text-light text-center">Figure 3: Block diagram of a section of a 2D digital waveguide mesh [6].</figcaption>
                </figure>
                <p>
                    Physical modelling synthesizers in the commercial space compete most directly with samplers, although they do also have some competition with other synthesis algorithms such as FM synthesis. The primary advantage of physical models over sample-based approaches for realistic acoustic instrument simulation lies in the flexibility of the parameters the player can control in the model, allowing for highly expressive performances and a bigger range of timbral variety from a single model [1, 7]. There is also the benefit that physical models use very little storage and have low RAM requirements when compared to industry standard sampling alternatives. For example, the huge difference is clear when comparing the size of Pianoteq, a physical modelling instrument, with Keyscape, an industry standard piano sampling library. Pianoteq requires just 50MB of storage space on the user’s computer, compared to Keyscape’s 77GB, and Pianoteq also requires just 256MB of RAM, compared to Keyscape’s minimum requirement of 8GB [8, 9, 10]. However, this does not mean that physical models are without issue. Physical modelling synthesizers generally utilise the CPU more heavily than sampling-based approaches, but with modern computing power this has become less of an issue. The biggest problem with physical modelling synthesis is the complexity involved with designing efficient algorithms for accurate and realistic sounding models of complex instruments with a wide range of parameters, particularly when compared with sampling based approaches which simply use digital audio playback along with post processing techniques such as filtering for timbral changes.
                </p>
                <p>
                    This article will detail the implementation of a physics inspired system of a resonated flute played in a virtual acoustic space, from the raw mathematics to the MATLAB code. There will be analysis performed to detail the success of the implementation and verify that it behaves as expected, as well as a range of “presets” showing the range of possible sounds it can create and discussion surrounding the limitations and potential future work of the project.
                </p>                
            </div>
            <div>
                <h3>2. System</h3>
                <p>
                    The resonated flute in the virtual acoustic space is built as 3 distinct parts, with each part then connected to one another. The modelled flute is based on the physical model for a slide flute, using the digital waveguide approach to synthesize the travelling waves within the bore of the flute. The equation for this was shown in section 1 of the article. The pitch of this is then adjusted by modifying the length of the delay line, thus in effect modifying the length of the bore. This model also features periodic amplitude modulation, or tremolo, to add to the realism of the sound.  The model features four adjustable parameters which alter the timbre of the model: pressure, which simulates how hard the flute is blown into; breath, which simulates how much “breath” sound comes through the flute; attack time, which affects the onset time of the note; and tremolo depth, the level of fluctuation in amplitude. The block diagram for a basic digital waveguide implementation of a slide flute is shown in Figure 4.
                </p>
                <figure class="figure w-100">
                    <div class="d-flex">
                        <img class="figure-img mx-auto" src="./basic-flute-block-diagram.PNG" alt="">
                    </div>
                    <figcaption style="font-style: italic;" class="figure-caption text-light text-center">Figure 4: Block diagram of a simple digital waveguide slide flute [11].</figcaption>
                </figure>
                <p>
                    The implementation detailed in this article has expanded upon the model from this block diagram by adding a flow envelope to control the amplitude of the input noise over time, as well as adding a third delay line of half the length of the existing at the input of the system, to simulate the delay of the player blowing across the mouthpiece of the flute [12]. The block diagram for this extended model is shown in Figure 5.
                </p>
                <figure class="figure w-100">
                    <div class="d-flex">
                        <img class="figure-img mx-auto" src="./extended-flute-block-diagram.PNG" alt="">
                    </div>
                    <figcaption style="font-style: italic;" class="figure-caption text-light text-center">Figure 5: Block diagram of an extended digital waveguide slide flute [12].</figcaption>
                </figure>
                <p>
                    The flute is then convolved by the impulse response of a physically modelled 2D absorbing membrane. This membrane is modelled using the FDTD equation and simulates the acoustic pressure across the membrane in all directions. The membrane’s response is implemented by considering the 2D differential wave equation:
                </p>
                <figure style="font-size: 125%;">
                    $$\frac{\partial u(t, x, y)}{\partial t^2} = c^2 \left(\frac{\partial^2 u(t, x, y)}{\partial x^2} + \frac{\partial^2 u(t, x, y)}{\partial y^2}\right)$$
                </figure>
                <p>
                    and then discretising this using the FDTD method:
                </p>
                <figure style="font-size: 125%;">
                    $$u_{x, y}^{n+1} = Au_{x, y}^n + B(u_{x+1, y}^n + u_{x-1, y}^n + u_{x, y+1}^n + u_{x, y-1}^n) + Cu_{x, y}^{n-1}$$
                </figure>
                <p>
                    where \(u_{l,h}^n\) is the acoustic pressure at coordinate \((l,h)\) on the membrane at sample point \(n\), and \(A\), \(B\), and \(C\) are the absorption coefficients. The size of the membrane is adjustable, as well as the size and location of the excitation point, the position that the output is sampled from, and the absorption coefficient at the boundaries. Convolving the output of the flute signal with the impulse response of this effectively causes the sound of the flute to be resonated by the membrane. There is also a mix control which balances the mix between dry sound and the convolved signal. 
                </p>
                <p>
                    The output of this is then processed through a virtual acoustic space reverberation, implemented based on the Moorer reverb algorithm using comb and all-pass filters, as well as a tapped delay line for the early reflections. The early reflection times and the gains of these reflections can be altered, as well as the feedback of the comb filters, which controls the reverberation time. There is also a mix control which balances the dry, direct sound with the reverberated signal. A diagram for the reverberation network is shown in Figure 6. 
                </p>
                <figure class="figure w-100">
                    <div class="d-flex">
                        <img class="figure-img mx-auto" width="550px" src="./moorer-reverb-with-er.PNG" alt="">
                    </div>
                    <figcaption style="font-style: italic; width: 550px;" class="figure-caption mx-auto text-light text-center">Figure 6: Digital reverberation network diagram, based on a reverberation network from [13] with the addition of the early reflections block (ER) [14]. Cn represent comb filters and An represent all pass filters.</figcaption>
                </figure>
            </div>
            <div>
                <h3>3. Examples</h3>
                <p>
                    The individual sections of the system will now be heard and analysed, and the interactions between these shown. Table 1 has an audio snippet of the flute section of the model playing an A4 (440Hz) along with its corresponding spectrogram.
                </p>
                <figure>
                    <table class="table text-light">
                        <tr>
                            <th>Audio</th>
                            <th>Waveform</th>
                            <th>Spectrogram</th>
                        </tr>
                        <tr>
                            <td class="align-middle">
                                <audio controls src="./audio/a4-flute-only.wav">
                            </td>
                            <td>
                                <img width="500px" src="./a4-flute-waveform.PNG" alt="">
                            </td>
                            <td>
                                <img width="500px" src="./a4-flute-spectrogram.PNG" alt="">
                            </td>
                        </tr>
                    </table>
                    <figcaption style="font-style: italic;" class="figure-caption text-light text-center">Table 1: Table providing an audio file of the modelled flute playing an A4, along with the corresponding waveform and spectrogram.</figcaption>
                </figure>
                <p>
                    This spectrogram shows that the fundamental frequency lies in approximately the right area of the spectrum for a 440Hz A4 but is roughly 20Hz flat. This is due to pitch quantization which occurs during the discretisation process, where the integer length of the delay lines causes inaccuracies in pitch. In an ideal case, without rounding errors and quantized delay lines, the number of samples in the delay line could be calculated as follows:
                </p>
                <figure style="font-size: 125%;">
                    $$ N_{left} = N_{right} = \left(0.25 \times \frac{F_s}{f_0}\right) = 0.25 \times \frac{48000}{440} = 27.\dot{2}\dot{7}\ samples$$
                </figure style="font-size: 125%;">
                <p>
                    The total bore length is therefore the summation of the length of both delay:
                </p>
                <figure style="font-size: 125%;">
                    $$ N_{bore} = N_{left} + N_{right} = 54.545\ samples $$
                </figure>
                <p>
                    Then calculating the oscillation period based on twice the delay period of the delay line [15]:
                </p>
                <figure style="font-size: 125%;">
                    $$ T_N = 2 \times N_{bore} = 2 \times 54.545 = 109.091\ samples $$
                </figure>
                <p>
                    Then finally converting this to metres and thus calculating the fundamental:
                </p>
                <figure style="font-size: 125%;">
                    $$ f_0 = \frac{1}{\frac{T_N}{F_s}} = \frac{1}{\frac{109.091}{48000}}= 440\ Hz $$
                </figure>
                <p>
                    The harmonic series visible in the spectrogram also matches that of a flute, where the harmonics are integer multiples of the fundamental frequency [16]. Table 2 shows the fundamental and first 4 harmonics.
                </p>
                <figure>
                    <table class="w-50 mx-auto table text-light">
                        <tr>
                            <th>
                                Harmonic
                            </th>
                            <th>
                                Relation to Fundamental
                            </th>
                            <th>
                                Measured Frequency
                            </th>
                        </tr>
                        <tr>
                            <td>
                                1<sup>st</sup>
                            </td>
                            <td>
                                \(f_0\)
                            </td>
                            <td>
                                421.98 Hz
                            </td>
                        </tr>
                        <tr>
                            <td>
                                2<sup>nd</sup>
                            </td>
                            <td>
                                \(2f_0\)
                            </td>
                            <td>
                                843.96 Hz
                            </td>
                        </tr>
                        <tr>
                            <td>
                                3<sup>rd</sup>
                            </td>
                            <td>
                                \(3f_0\)
                            </td>
                            <td>
                                1265.93 Hz
                            </td>
                        </tr>
                        <tr>
                            <td>
                                4<sup>th</sup>
                            </td>
                            <td>
                                \(4f_0\)
                            </td>
                            <td>
                                1687.91 Hz
                            </td>
                        </tr>
                    </table>
                    <figcaption style="font-style: italic;" class="w-50 mx-auto figure-caption text-light text-center">Table 2: Table showing measured harmonic values alongside their expected relation to the fundamental frequency.</figcaption>
                </figure>
                <p>
                    The small levels of inharmonic frequencies across the spectrum show the noise from the breath input to the system.
                </p>
                <p>
                    An example audio clip of the absorbing membrane’s response can be heard in Table 3, and the corresponding waveform and spectrogram can also be seen.
                </p>
                <figure>
                    <table class="table text-light">
                        <tr>
                            <th>Audio</th>
                            <th>Waveform</th>
                            <th>Spectrogram</th>
                        </tr>
                        <tr>
                            <td class="align-middle">
                                <audio controls src="./audio/membrane-response.wav">
                            </td>
                            <td>
                                <img width="500px" src="./membrane-waveform.PNG" alt="">
                            </td>
                            <td>
                                <img width="473px" src="./membrane-spectrum.PNG" alt="">
                            </td>
                        </tr>
                    </table>
                    <figcaption style="font-style: italic;" class="figure-caption text-light text-center">Table 3: Table providing an audio file of the modelled absorbing membrane of length 66cm and width 12cm, along with the corresponding waveform and spectrogram.</figcaption>
                </figure>
                <p>
                    The spectrogram shown in Table 3 clearly shows the resonant modes of the membrane through the repeated spikes. The values of these are shown in Table 4. These modes can be altered by changing the dimensions of the membrane, the position or size of the excitation, and the position the output is measured from.
                </p>
                <figure>
                    <table class="table w-50 mx-auto text-light">
                        <tr>
                            <th>
                                Resonant Peak
                            </th>
                            <th>
                                Frequency
                            </th>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>216.85 Hz</td>
                        </tr>
                        <tr>
                            <td>
                                2
                            </td>
                            <td>
                                433.70 Hz
                            </td>
                        </tr>
                        <tr>
                            <td>
                                3
                            </td>
                            <td>
                                656.41 Hz
                            </td>
                        </tr>
                        <tr>
                            <td>
                                4
                            </td>
                            <td>
                                890.84 Hz
                            </td>
                        </tr>
                        <tr>
                            <td>
                                5
                            </td>
                            <td>
                                1131.1 Hz
                            </td>
                        </tr>
                    </table>
                    <figcaption style="font-style: italic;" class="w-50 mx-auto figure-caption text-light text-center">Table 4: Table showing the resonant mode peak frequencies from the modelled absorbing membrane of length 66cm and width 12cm.</figcaption>
                </figure>
                <p>
                    When the output of the modelled flute playing an A4 is convolved with the response of the membrane, this alters the frequency response, boosting it at the resonant mode peaks and attenuating it at other points. This can be seen in Figure 7, where the convolved signal’s frequency spectrum has a higher peak at the resonant frequency than the non-convolved signal, as well as having lower values at other, non-resonant points of the membrane’s frequency response.
                </p>
                <figure class="figure w-100">
                    <div class="d-flex">
                        <img class="figure-img mx-auto" width="550px" src="./convolved-vs-not-spectrum.PNG" alt="">
                    </div>
                    <figcaption style="font-style: italic; width: 550px;" class="figure-caption mx-auto text-light text-center">Figure 7: Spectrogram showing the frequency response of the membrane, compared to the frequency responses of the non-convolved flute and the convolved flute. The peaks have been labelled with dotted lines to highlight the difference.</figcaption>
                </figure>
                <p>
                    The third section of the system is the Moorer reverb implementation. An impulse response of a room 30 metres long and 20 metres wide can be seen and heard in Table 5, along with the isolated early reflections. 
                </p>
                <figure>
                    <table class="table">
                        <tr>
                            <th>
                                Audio
                            </th>
                            <th>
                                Waveform
                            </th>
                            <th>
                                Early Reflections
                            </th>
                        </tr>
                        <tr>
                            <td class="align-middle">
                                <audio controls src="./audio/big-room-ir.wav">
                            </td>
                            <td>
                                <img src="./reverb-waveform.PNG" width="500px" alt="">
                            </td>
                            <td>
                                <img src="./early-reflections.PNG" width="499px" alt="">
                            </td>
                        </tr>
                    </table>
                    <figcaption style="font-style: italic;" class="w-50 mx-auto figure-caption text-light text-center">Table 5: Table showing the impulse response and early reflections of a simulated room which is 30 metres long and 20 metres wide.</figcaption>
                </figure>
                <p>
                    The isolated early reflections show that the tapped delay line is behaving as expected, with the reflections falling at the correct points in the time domain. The early reflection times are shown in Table 6, along with the given early reflection times. The given times were calculated based on the delay times and approximate amplitudes gathered from [19]. 
                </p>
                <figure>
                    <table class="table text-light w-50 mx-auto">
                        <tr>
                            <th>
                                Given ER Time (ms)
                            </th>
                            <th>
                                Measured ER Time (ms)
                            </th>
                        </tr>
                        <tr>
                            <td>
                                65.20
                            </td>
                            <td>
                                65.1889
                            </td>
                        </tr>
                        <tr>
                            <td>
                                81.90
                            </td>
                            <td>
                                81.8975
                            </td>
                        </tr>
                        <tr>
                            <td>
                                83.70
                            </td>
                            <td>
                                83.6892
                            </td>
                        </tr>
                        <tr>
                            <td>
                                85.80
                            </td>
                            <td>
                                85.7935
                            </td>
                        </tr>
                        <tr>
                            <td>
                                89.30
                            </td>
                            <td>
                                89.2935
                            </td>
                        </tr>
                        <tr>
                            <td>
                                103.2
                            </td>
                            <td>
                                103.190
                            </td>
                        </tr>
                        <tr>
                            <td>
                                104.7
                            </td>
                            <td>
                                104.690
                            </td>
                        </tr>
                        <tr>
                            <td>
                                106.1
                            </td>
                            <td>
                                106.086
                            </td>
                        </tr>
                        <tr>
                            <td>
                                107.5
                            </td>
                            <td>
                                107.502
                            </td>
                        </tr>
                        <tr>
                            <td>
                                116.6
                            </td>
                            <td>
                                116.586
                            </td>
                        </tr>
                        <tr>
                            <td>
                                131.000
                            </td>
                            <td>
                                131.003
                            </td>
                        </tr>
                        <tr>
                            <td>
                                233.500
                            </td>
                            <td>
                                233.521
                            </td>
                        </tr>
                    </table>
                    <figcaption style="font-style: italic;" class="w-50 mx-auto figure-caption text-light text-center">Table 6: Table showing the target early reflection times compared to the measured early reflection times.</figcaption>
                </figure>
                <p>
                    Changing the early reflection times changes the size and shape of the room being simulated. Adjusting the comb filter feedback gain also has an impact on the perceived room size and can vastly affect the \(RT_{60}\) of the system. The \(RT_{60}\)  can be estimated by plotting the impulse response normalized to unity gain (0dB), plotting a horizontal line at -60dB against this and then finding the point at which the amplitude does not rise above -60dB again. Figure 8 shows this plot for the simulated room shown in Table 5, with the \(RT_{60}\) of approximately 845ms labelled.
                </p>
                <figure class="figure w-100">
                    <div class="d-flex">
                        <img class="figure-img mx-auto" src="./rt60-estimation.PNG" alt="">
                    </div>
                    <figcaption style="font-style: italic; width: 550px;" class="figure-caption mx-auto text-light text-center">Figure 8: \(RT_{60}\) estimation using a normalized impulse response plot for a 30 metre long and 20 metre wide simulated room.</figcaption>
                </figure>
            </div>
            <div>
                <h3>4. Presets</h3>
                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore
                    et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut
                    aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
                    cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
                    culpa qui officia deserunt mollit anim id est laborum.
                </p>
            </div>
            <div>
                <h3>5. Conclusion</h3>
                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore
                    et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut
                    aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
                    cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
                    culpa qui officia deserunt mollit anim id est laborum.
                </p>
            </div>
            <div>
                <h3>6. Limitations & Future Work</h3>
                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore
                    et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut
                    aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
                    cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
                    culpa qui officia deserunt mollit anim id est laborum.</p>
            </div>
            <div style="text-align: left;" >
                <h3>6. References</h3>
                <ol class="ref-list">
                    <li>O. Smith, ‘Physical Modeling Using Digital Waveguides’, Computer Music Journal, vol. 16, no. 4, pp. 74–91, 1992.</li>
                    <li>G. Loy, Musimathics, Volume 2. The MIT Press, 2007.</li>
                    <li>M. N. O. Sadiku, Numerical Techniques in Electromagnetics. CRC Press, 2000.</li>
                    <li>Stanford University News Service, ‘Music synthesis approaches sound quality of real instruments’, 1994 [Online]. Available: https://news.stanford.edu/pr/94/940607Arc4222.html.</li>
                    <li>Modartt, Modartt - Pianoteq 7. [Online]. Available: https://www.modartt.com/pianoteq. [Accessed: 29 Dec. 2020].</li>
                    <li>S. Van Duyne and J. O. Smith, ‘The 2-D digital waveguide mesh’, in Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, 1993, pp. 177–180.</li>
                </ol>
            </div>
        </div>
    </div>
</body>

</html>